[![My GitHub stats](https://github-readme-stats.vercel.app/api?username=Tomorrowdawn&count_private=True)](https://github.com/anuraghazra/github-readme-stats)

<div align="center">
  
  ![](https://komarev.com/ghpvc/?username=Tomorrowdawn) ![GitHub User's stars](https://img.shields.io/github/stars/Tomorrowdawn) 
  
</div>

## Hi there ðŸ‘‹

<img align="right" width="200" src="https://hips.hearstapps.com/hmg-prod/images/euripides-9289335-1-402.jpg" alt="Euripides">

Torrowdawn, or *Chenxia Tang* here. 

I was born in 2003, and I'm currently a Master student in USTC. My main research interest is deep learning, with a particular focus on pre-training and high-speed inference. I agree with Euripides: *The language of truth is simple*.

My favorite Top-2 English words are *Meditation* and *Philosophy*. I treat meditation as the best medicine for life, and I also deeply love wisdom. 

### ðŸ’» Skills

I am highly proficient in 

- Python ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
- C++ ![C++](https://img.shields.io/badge/c++-%2300599C.svg?style=for-the-badge&logo=c%2B%2B&logoColor=white)

which you can verify from my repos. I also wrote `verilog`, and planning to learn dart to develop some android apps.

---

### ðŸ”¬ Research Interests

I have dabbled in

- Reinforcement Learning
- Recommendation System
- Large Language Model

My research on large language models is particularly **in-depth**. I tried RLHF(GPT-2 scale), finetuning(LLaMA2, 3). I have measured the execution times of almost all operators in LLAMA, and I am quite familiar with the bottlenecks of LLaMA, at least of single-GPU execution on the A6000.



---

### ðŸŽ“ Education

- Bachelor's Degree

<p align="right">
<em>University of Science and Technology of China (USTC) <br> Special Class for the Gifted Young (enrolled at age 16) <br> 2019 -2023</em>
</p>

- Master's Degree(Now)

<p align="right">
<em>University of Science and Technology of China (USTC) <br> School of Computer Science and Technology <br> 2023 - </em>
</p>

I served as a teaching assistantï¼ˆTAï¼‰ for *Algebra*ï¼Œin 2023 fall.

### Projects


